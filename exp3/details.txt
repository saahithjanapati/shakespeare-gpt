RoPE Embeddings + a standard 6-layer GPT, 8 head, 128 embd-dim, block size 128, trained for one epoch